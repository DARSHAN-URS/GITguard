const logger = require('./logger');
const { estimateTokens } = require('./tokenManager');

/**
 * Generates system instructions (shared across all chunks)
 * @param {Object} prData - Pull request metadata
 * @param {Object} settings - Repository settings
 * @returns {string} - System instructions
 */
function generateSystemInstructions(prData, settings = {}) {
  let instructions = `# Code Review Request\n\n`;
  instructions += `## Pull Request Information\n`;
  instructions += `- **Repository:** ${prData.repository}\n`;
  instructions += `- **PR Number:** #${prData.pullRequestNumber}\n`;
  instructions += `- **Title:** ${prData.title}\n`;
  instructions += `- **Author:** ${prData.author}\n`;
  instructions += `- **Action:** ${prData.action}\n\n`;

  instructions += `## Review Instructions\n`;
  instructions += `Analyze ONLY the changed code below and generate actionable review feedback suitable for posting directly as a GitHub Pull Request review comment.\n\n`;

  if (settings.strictMode) {
    instructions += `**⚠️ STRICT MODE ENABLED:** Be more thorough and flag even minor issues.\n\n`;
  }

  instructions += `**Focus Areas:**\n`;
  instructions += `1. **Bugs**: Logical errors, incorrect conditions, edge-case failures, broken functionality\n`;
  instructions += `2. **Security**: Hardcoded secrets, unsafe input handling, injection vulnerabilities, insecure API usage\n`;
  instructions += `3. **Performance**: Inefficient loops, unnecessary computations, redundant API calls, bottlenecks\n`;

  if (!settings.ignoreStyling && !settings.ignoreLinter) {
    instructions += `4. **Quality**: Readability, maintainability, error handling, best practices\n\n`;
  } else {
    instructions += `4. **Quality**: Readability, maintainability, error handling, best practices\n`;
    instructions += `   ${settings.ignoreStyling ? '⚠️ **IGNORE STYLING ISSUES** - Skip formatting/style checks\n' : ''}`;
    instructions += `   ${settings.ignoreLinter ? '⚠️ **IGNORE LINTER ISSUES** - Skip linter warnings\n' : ''}`;
    instructions += `\n`;
  }

  instructions += `**Output Format:** For each issue found, provide:\n`;
  instructions += `- **Title**: Short, descriptive title\n`;
  instructions += `- **Type**: One of: Bug, Security, Performance, or Quality\n`;
  instructions += `- **Explanation**: Clear explanation of the issue\n`;
  instructions += `- **Suggested Fix**: Minimal corrected code snippet (only relevant changed lines)\n\n`;

  instructions += `**Constraints:**\n`;
  instructions += `- Do NOT analyze unchanged code\n`;
  instructions += `- Do NOT invent problems or assume missing context\n`;
  instructions += `- Do NOT include sensitive information\n`;

  if (settings.ignoreStyling) {
    instructions += `- Do NOT flag formatting, indentation, or style-only issues\n`;
  }
  if (settings.ignoreLinter) {
    instructions += `- Do NOT flag linter warnings or code style violations\n`;
  }
  if (!settings.ignoreStyling && !settings.ignoreLinter) {
    instructions += `- Do NOT focus on minor formatting/style-only issues unless they impact correctness\n`;
  }

  instructions += `- Keep explanations concise and developer-friendly\n\n`;
  instructions += `**No-Issue Case:** If no critical issues are found, explicitly state: "✅ No critical issues detected. The code meets acceptable standards for correctness, security, and performance."\n\n`;

  return instructions;
}

/**
 * Generates a file-level prompt for a single file (or chunk)
 * @param {Object} prData - Pull request metadata
 * @param {Object} file - File diff object
 * @param {Object} settings - Repository settings
 * @param {Object} options - Additional options (chunkIndex, totalChunks, isChunk)
 * @returns {string} - File-level prompt
 */
function generateFilePrompt(prData, file, settings = {}, options = {}) {
  const { chunkIndex, totalChunks, isChunk = false } = options;
  
  let prompt = generateSystemInstructions(prData, settings);
  
  prompt += `## Code Changes\n\n`;
  
  if (isChunk && totalChunks > 1) {
    prompt += `**⚠️ IMPORTANT: This is part ${chunkIndex + 1} of ${totalChunks} for this file.**\n`;
    prompt += `Review ONLY the code shown below. Do NOT repeat feedback from other chunks.\n\n`;
  }
  
  prompt += `### File: \`${file.filename}\`\n`;
  prompt += `**Language:** ${file.language}\n`;
  if (file.status) {
    prompt += `**Status:** ${file.status}\n`;
  }
  if (file.additions !== undefined && file.deletions !== undefined) {
    prompt += `**Changes:** +${file.additions} / -${file.deletions} lines\n`;
  }
  prompt += `\n\`\`\`${file.language}\n`;
  prompt += `${file.changes}\n`;
  prompt += `\`\`\`\n\n`;

  prompt += `## Review Output\n\n`;
  prompt += `Provide your review feedback in the format specified above. Format your response using GitHub-flavored Markdown for readability.\n\n`;
  prompt += `---\n`;
  prompt += `*Generated by GitGuard AI - Automated Code Review System*\n`;

  return prompt;
}

/**
 * Generates an LLM prompt for code review analysis with cleaned diffs
 * @param {Object} prData - Pull request metadata
 * @param {Array} cleanedDiff - Array of cleaned file diffs
 * @param {Object} settings - Repository settings (Week 4)
 * @returns {string} - Formatted LLM prompt
 */
function generateLLMPrompt(prData, cleanedDiff, settings = {}) {
  try {
    if (!cleanedDiff || cleanedDiff.length === 0) {
      logger.warn('No cleaned diff available for prompt generation');
      return null;
    }

    // Build the prompt structure
    let prompt = `# Code Review Request\n\n`;
    
    // PR Metadata
    prompt += `## Pull Request Information\n`;
    prompt += `- **Repository:** ${prData.repository}\n`;
    prompt += `- **PR Number:** #${prData.pullRequestNumber}\n`;
    prompt += `- **Title:** ${prData.title}\n`;
    prompt += `- **Author:** ${prData.author}\n`;
    prompt += `- **Action:** ${prData.action}\n\n`;

    // Instructions for LLM (Week 3 Requirements + Week 4 Settings)
    prompt += `## Review Instructions\n`;
    prompt += `Analyze ONLY the changed code below and generate actionable review feedback suitable for posting directly as a GitHub Pull Request review comment.\n\n`;
    
    // Week 4: Apply repository settings
    if (settings.strictMode) {
      prompt += `**⚠️ STRICT MODE ENABLED:** Be more thorough and flag even minor issues.\n\n`;
    }
    
    prompt += `**Focus Areas:**\n`;
    prompt += `1. **Bugs**: Logical errors, incorrect conditions, edge-case failures, broken functionality\n`;
    prompt += `2. **Security**: Hardcoded secrets, unsafe input handling, injection vulnerabilities, insecure API usage\n`;
    prompt += `3. **Performance**: Inefficient loops, unnecessary computations, redundant API calls, bottlenecks\n`;
    
    // Week 4: Conditionally include Quality based on settings
    if (!settings.ignoreStyling && !settings.ignoreLinter) {
      prompt += `4. **Quality**: Readability, maintainability, error handling, best practices\n\n`;
    } else {
      prompt += `4. **Quality**: Readability, maintainability, error handling, best practices\n`;
      prompt += `   ${settings.ignoreStyling ? '⚠️ **IGNORE STYLING ISSUES** - Skip formatting/style checks\n' : ''}`;
      prompt += `   ${settings.ignoreLinter ? '⚠️ **IGNORE LINTER ISSUES** - Skip linter warnings\n' : ''}`;
      prompt += `\n`;
    }
    
    prompt += `**Output Format:** For each issue found, provide:\n`;
    prompt += `- **Title**: Short, descriptive title\n`;
    prompt += `- **Type**: One of: Bug, Security, Performance, or Quality\n`;
    prompt += `- **Explanation**: Clear explanation of the issue\n`;
    prompt += `- **Suggested Fix**: Minimal corrected code snippet (only relevant changed lines)\n\n`;
    prompt += `**Constraints:**\n`;
    prompt += `- Do NOT analyze unchanged code\n`;
    prompt += `- Do NOT invent problems or assume missing context\n`;
    prompt += `- Do NOT include sensitive information\n`;
    
    // Week 4: Apply ignore settings
    if (settings.ignoreStyling) {
      prompt += `- Do NOT flag formatting, indentation, or style-only issues\n`;
    }
    if (settings.ignoreLinter) {
      prompt += `- Do NOT flag linter warnings or code style violations\n`;
    }
    if (!settings.ignoreStyling && !settings.ignoreLinter) {
      prompt += `- Do NOT focus on minor formatting/style-only issues unless they impact correctness\n`;
    }
    
    prompt += `- Keep explanations concise and developer-friendly\n\n`;
    prompt += `**No-Issue Case:** If no critical issues are found, explicitly state: "✅ No critical issues detected. The code meets acceptable standards for correctness, security, and performance."\n\n`;

    // Code Changes
    prompt += `## Code Changes\n\n`;
    
    for (let i = 0; i < cleanedDiff.length; i++) {
      const file = cleanedDiff[i];
      
      prompt += `### File ${i + 1}: \`${file.filename}\`\n`;
      prompt += `**Language:** ${file.language}\n`;
      if (file.status) {
        prompt += `**Status:** ${file.status}\n`;
      }
      if (file.additions !== undefined && file.deletions !== undefined) {
        prompt += `**Changes:** +${file.additions} / -${file.deletions} lines\n`;
      }
      prompt += `\n\`\`\`${file.language}\n`;
      prompt += `${file.changes}\n`;
      prompt += `\`\`\`\n\n`;
    }

    // Analysis Request
    prompt += `## Review Output\n\n`;
    prompt += `Provide your review feedback in the format specified above. Format your response using GitHub-flavored Markdown for readability.\n\n`;

    prompt += `---\n`;
    prompt += `*Generated by GitGuard AI - Automated Code Review System*\n`;

    return prompt;

  } catch (error) {
    logger.error('Error generating LLM prompt', {
      error: error.message,
      stack: error.stack
    });
    throw error;
  }
}

/**
 * Generates a compact LLM prompt (token-efficient version)
 * @param {Object} prData - Pull request metadata
 * @param {Array} cleanedDiff - Array of cleaned file diffs
 * @param {Object} settings - Repository settings (Week 4)
 * @returns {string} - Compact formatted LLM prompt
 */
function generateCompactLLMPrompt(prData, cleanedDiff, settings = {}) {
  try {
    if (!cleanedDiff || cleanedDiff.length === 0) {
      return null;
    }

    // Compact format for token efficiency
    let prompt = `Review PR #${prData.pullRequestNumber} in ${prData.repository} by ${prData.author}.\n`;
    prompt += `Title: ${prData.title}\n\n`;
    prompt += `Analyze for: bugs, security issues, performance, code quality.\n\n`;

    for (const file of cleanedDiff) {
      prompt += `File: ${file.filename} (${file.language})\n`;
      prompt += `\`\`\`${file.language}\n${file.changes}\n\`\`\`\n\n`;
    }

    prompt += `Provide: issues, suggestions, and priority levels.`;

    return prompt;

  } catch (error) {
    logger.error('Error generating compact LLM prompt', {
      error: error.message
    });
    throw error;
  }
}

/**
 * Generates file-level prompts (one per file, chunked if needed)
 * @param {Object} prData - Pull request metadata
 * @param {Array} cleanedDiff - Array of cleaned file diffs
 * @param {Object} settings - Repository settings
 * @returns {Array<Object>} - Array of prompt objects (one per file/chunk)
 */
function generateFileLevelPrompts(prData, cleanedDiff, settings = {}) {
  const { validatePromptTokens, chunkFileContent, MAX_TOKENS_PER_REQUEST } = require('./tokenManager');
  const prompts = [];

  for (const file of cleanedDiff) {
    // Generate base prompt for this file
    const basePrompt = generateFilePrompt(prData, file, settings);
    const validation = validatePromptTokens(basePrompt);

    if (validation.isValid) {
      // File fits in one prompt
      prompts.push({
        prompt: basePrompt,
        filename: file.filename,
        fileIndex: cleanedDiff.indexOf(file),
        chunkIndex: 0,
        totalChunks: 1,
        isChunk: false,
        estimatedTokens: validation.estimatedTokens
      });
    } else {
      // File needs chunking
      const chunks = chunkFileContent(file.changes, MAX_TOKENS_PER_REQUEST - estimateTokens(generateSystemInstructions(prData, settings)) - 500); // Reserve 500 tokens for file metadata
      
      for (let i = 0; i < chunks.length; i++) {
        const chunkedFile = {
          ...file,
          changes: chunks[i]
        };
        
        const chunkPrompt = generateFilePrompt(prData, chunkedFile, settings, {
          chunkIndex: i,
          totalChunks: chunks.length,
          isChunk: true
        });
        
        const chunkValidation = validatePromptTokens(chunkPrompt);
        
        prompts.push({
          prompt: chunkPrompt,
          filename: file.filename,
          fileIndex: cleanedDiff.indexOf(file),
          chunkIndex: i,
          totalChunks: chunks.length,
          isChunk: true,
          estimatedTokens: chunkValidation.estimatedTokens
        });
      }
    }
  }

  return prompts;
}

/**
 * Generates structured prompt data for API consumption
 * @param {Object} prData - Pull request metadata
 * @param {Array} cleanedDiff - Array of cleaned file diffs
 * @param {string} format - 'full' or 'compact'
 * @param {Object} settings - Repository settings (Week 4)
 * @returns {Object} - Structured prompt data (legacy format for backward compatibility)
 */
function generateStructuredPrompt(prData, cleanedDiff, format = 'full', settings = {}) {
  try {
    // For backward compatibility, still generate single prompt
    // But this should only be used for viewing/debugging, not for LLM calls
    const promptText = format === 'compact' 
      ? generateCompactLLMPrompt(prData, cleanedDiff, settings)
      : generateLLMPrompt(prData, cleanedDiff, settings);

    if (!promptText) {
      return null;
    }

    const estimatedTokens = estimateTokens(promptText);

    return {
      prompt: promptText,
      format: format,
      estimatedTokens: estimatedTokens,
      fileCount: cleanedDiff.length,
      totalChanges: cleanedDiff.reduce((sum, file) => sum + (file.changes?.length || 0), 0),
      generatedAt: new Date().toISOString()
    };

  } catch (error) {
    logger.error('Error generating structured prompt', {
      error: error.message
    });
    throw error;
  }
}

module.exports = {
  generateLLMPrompt,
  generateCompactLLMPrompt,
  generateStructuredPrompt,
  generateFileLevelPrompts,
  generateFilePrompt,
  generateSystemInstructions
};
